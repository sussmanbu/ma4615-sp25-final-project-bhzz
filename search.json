[
  {
    "objectID": "posts/fifth-blog-post/5thblogpost.html",
    "href": "posts/fifth-blog-post/5thblogpost.html",
    "title": "5thBlogPost",
    "section": "",
    "text": "Dataset: https://data.census.gov/table/ACSST1Y2023.S0601?q=Chicago+Demographics We combined our violent crime victim data with 2023 ACS 1-Year estimates for Chicago, which provide demographic breakdowns of sex and race across the city.\nHow to combine? We can use the TIME_PERIOD, RACE, and AGE variables in the victim dataset to connect with the RACE, AGE, and YEAR variables in this demographics dataset. The new dataset containing the variables of marital status, education level, personal income, and poverty status would provide more information and probably give more insights into the reasons for the crime conviction.\nInitial findings: After briefly looking through the new dataset, we found that while the black individuals make up only 27.9% of the population, they account for over 50% of homicide and battery victims. Other than that, as females represent around 51.5% of the population, in the sexual assault crimes, they are disproportionately represented, which will be the part we will continue exploring the reasons behind.\nPossible challenges and Next Steps: Since the race categorization in the new dataset is different from the victim data, and we are not quite sure about some race types in he victim data, it may be a problem we need to keep working on. And then we will start working on combining the data, making some visuals, and interpreting the results."
  },
  {
    "objectID": "posts/2025-4-22-sixth-blog-post/6thblogpost.html",
    "href": "posts/2025-4-22-sixth-blog-post/6thblogpost.html",
    "title": "Sixth blog post",
    "section": "",
    "text": "Final Steps As our team approaches the final stages of the project, we’ve assessed our progress to identify areas of the project where more work is needed. We’ve successfully conducted an indepth analysis and produced several charts/graphs highlighting demographic differences in violent crime victimization in Chicago. Our visuals include clear breakdowns by sex and race, and support a story about inequalities in crime victimization. We’ve also formulated a preliminary narrative thesis highlighting the significant disparities based on sex and race to form the foundation of the Big Picture article.\nThe first task we still need to complete is the interactive dashboard component. We have a template and dataset ready, but we still need to finalize our Shiny dashboard to make sure it supports our narrative by allowing users to explore different demographics interactively. Also, we’re editing our Big Picture article’s to create an engaging, clear, and informative style similar to popular media. Next steps include finalizing a creative and engaging headline, finishing the explanatory text around each visualization, and making sure the interactive components flow with the narrative."
  },
  {
    "objectID": "posts/2025-3-31-fourth-blog-post/4thBlogPost.html",
    "href": "posts/2025-3-31-fourth-blog-post/4thBlogPost.html",
    "title": "4thBlogPost",
    "section": "",
    "text": "library(readr)\nViolence &lt;- read_csv(\"scripts/Violence_clean_missing.csv\")\n\nRows: 51070 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): TIME_PERIOD, TIME_PERIOD_START, TIME_PERIOD_END, PRIMARY_TYPE, AGE,...\ndbl (2): NUMBER_OF_VICTIMS, Year\nlgl (2): JUVENILE_I, DOMESTIC_I\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Load packages\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(broom)\nlibrary(ggeffects) # for prediction plotting\n \n# Step 1: Create binary response variable\nViolence_clean &lt;- Violence |&gt;\n  filter(!is.na(SEX), !is.na(RACE), !is.na(PRIMARY_TYPE)) |&gt;\n  mutate(\n    IS_SEXUAL_ASSAULT = ifelse(PRIMARY_TYPE == \"CRIMINAL SEXUAL ASSAULT\", 1, 0),\n    SEX = factor(SEX),\n    RACE = factor(RACE)\n  )\n \n# Step 2: Fit logistic regression\nmodel &lt;- glm(IS_SEXUAL_ASSAULT ~ SEX * RACE, data = Violence_clean, family = \"binomial\")\n \n# Step 3: Summarize model\nsummary(model)\n\n\nCall:\nglm(formula = IS_SEXUAL_ASSAULT ~ SEX * RACE, family = \"binomial\", \n    data = Violence_clean)\n\nCoefficients: (3 not defined because of singularities)\n                         Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            -1.495e+00  6.072e-02 -24.626  &lt; 2e-16 ***\nSEXM                   -2.473e+00  1.672e-01 -14.794  &lt; 2e-16 ***\nSEXUNKNOWN             -1.683e+00  1.022e+00  -1.646   0.0998 .  \nRACEBLK                -1.416e-01  6.781e-02  -2.089   0.0367 *  \nRACEI                  -2.850e-01  1.739e-01  -1.639   0.1013    \nRACES                  -7.598e+00  9.848e+01  -0.077   0.9385    \nRACEUNKNOWN             5.658e-02  8.115e-02   0.697   0.4856    \nRACEWBH                 4.771e-04  9.645e-02   0.005   0.9961    \nRACEWHI                 1.670e-01  6.993e-02   2.388   0.0169 *  \nRACEWWH                 7.226e-02  6.985e-02   1.035   0.3009    \nSEXM:RACEBLK            1.614e+00  1.747e-01   9.240  &lt; 2e-16 ***\nSEXUNKNOWN:RACEBLK      3.290e-01  1.048e+00   0.314   0.7536    \nSEXM:RACEI             -4.153e-01  4.458e-01  -0.932   0.3515    \nSEXUNKNOWN:RACEI       -8.103e+00  1.137e+02  -0.071   0.9432    \nSEXM:RACES                     NA         NA      NA       NA    \nSEXUNKNOWN:RACES               NA         NA      NA       NA    \nSEXM:RACEUNKNOWN        1.065e+00  1.979e-01   5.380 7.44e-08 ***\nSEXUNKNOWN:RACEUNKNOWN         NA         NA      NA       NA    \nSEXM:RACEWBH            1.761e-01  2.459e-01   0.716   0.4740    \nSEXUNKNOWN:RACEWBH      1.098e+00  1.475e+00   0.744   0.4566    \nSEXM:RACEWHI            1.364e+00  1.784e-01   7.647 2.05e-14 ***\nSEXUNKNOWN:RACEWHI      4.796e-01  1.096e+00   0.438   0.6616    \nSEXM:RACEWWH            1.319e+00  1.783e-01   7.402 1.34e-13 ***\nSEXUNKNOWN:RACEWWH      9.827e-01  1.061e+00   0.926   0.3545    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 37548  on 51069  degrees of freedom\nResidual deviance: 35408  on 51049  degrees of freedom\nAIC: 35450\n\nNumber of Fisher Scoring iterations: 10\n\n# Optional: Tidy output\ntidy(model, exponentiate = TRUE, conf.int = TRUE)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\nWarning in regularize.values(x, y, ties, missing(ties), na.rm = na.rm):\ncollapsing to unique 'x' values\n\n\n# A tibble: 24 × 7\n   term        estimate std.error statistic   p.value conf.low conf.high\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept) 0.224       0.0607 -24.6     6.72e-134   0.199      0.252\n 2 SEXM        0.0843      0.167  -14.8     1.60e- 49   0.0599     0.116\n 3 SEXUNKNOWN  0.186       1.02    -1.65    9.98e-  2   0.0104     0.884\n 4 RACEBLK     0.868       0.0678  -2.09    3.67e-  2   0.761      0.992\n 5 RACEI       0.752       0.174   -1.64    1.01e-  1   0.529      1.05 \n 6 RACES       0.000502   98.5     -0.0771  9.39e-  1  NA         40.0  \n 7 RACEUNKNOWN 1.06        0.0811   0.697   4.86e-  1   0.903      1.24 \n 8 RACEWBH     1.00        0.0965   0.00495 9.96e-  1   0.827      1.21 \n 9 RACEWHI     1.18        0.0699   2.39    1.69e-  2   1.03       1.36 \n10 RACEWWH     1.07        0.0699   1.03    3.01e-  1   0.938      1.23 \n# ℹ 14 more rows\n\n# Step 4: Plot predicted probabilities\npred &lt;- ggpredict(model, terms = c(\"SEX\", \"RACE\"))\nplot(pred) + \n  labs(title = \"Predicted probability of sexual assault victimization\",\n       y = \"Probability\", x = \"Sex\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/2025-3-19-third-blog-post/third blog post.html",
    "href": "posts/2025-3-19-third-blog-post/third blog post.html",
    "title": "Third blog post",
    "section": "",
    "text": "During the data loading and cleaning process, several columns with missing values marked as “UNKNOWN” were identified, including “AGE,” “SEX,” and “RACE.” Notably, the “GUNSHOT_INJURY_I” column often shows “UNKNOWN” before 2010 due to unavailable shooting data, which is not treated as true missing information. The cleaning process focuses primarily on “AGE,” “SEX,” and “RACE.” Around 1,000 records with two missing values—often due to suspects refusing to provide demographic information—are excluded. The final dataset retains rows with fewer than two missing values to ensure critical demographic data is available for analysis."
  },
  {
    "objectID": "posts/2025-3-19-third-blog-post/third blog post.html#data-loading-and-cleaning",
    "href": "posts/2025-3-19-third-blog-post/third blog post.html#data-loading-and-cleaning",
    "title": "Third blog post",
    "section": "",
    "text": "During the data loading and cleaning process, several columns with missing values marked as “UNKNOWN” were identified, including “AGE,” “SEX,” and “RACE.” Notably, the “GUNSHOT_INJURY_I” column often shows “UNKNOWN” before 2010 due to unavailable shooting data, which is not treated as true missing information. The cleaning process focuses primarily on “AGE,” “SEX,” and “RACE.” Around 1,000 records with two missing values—often due to suspects refusing to provide demographic information—are excluded. The final dataset retains rows with fewer than two missing values to ensure critical demographic data is available for analysis."
  },
  {
    "objectID": "posts/2025-3-19-third-blog-post/third blog post.html#data-for-equity",
    "href": "posts/2025-3-19-third-blog-post/third blog post.html#data-for-equity",
    "title": "Third blog post",
    "section": "Data for Equity:",
    "text": "Data for Equity:\n\nApplying the principles of Beneficence, Respect for Persons, and Justice ensures a responsible and ethical approach to analyzing the Chicago Violence Reduction Dataset. Beneficence emphasizes maximizing the benefits of this dataset by using it to inform violence prevention strategies while minimizing harm by avoiding misinterpretation that could reinforce harmful stereotypes or justify over-policing. Respect for Persons highlights the importance of protecting victim privacy, acknowledging the limitations of missing demographic data and ensuring that data cleaning methods do not introduce bias or erase marginalized groups from analysis. Justice calls for fair representation in data use, recognizing that underreported crimes and the exclusion of non-index crimes create gaps that could misdirect policy decisions. To uphold these principles, transparency about data limitations is essential, findings should be contextualized to avoid misrepresentation, and the dataset should be used alongside other sources to develop equitable, community-driven solutions to violence prevention in Chicago."
  },
  {
    "objectID": "posts/2025-3-17-second-blog-post/second blog post.html",
    "href": "posts/2025-3-17-second-blog-post/second blog post.html",
    "title": "Second blog post",
    "section": "",
    "text": "The data comes from the City of Chicago’s government and is collected by the Chicago Police Department (CPD) to track and analyze violent crimes, with a specific focus on gun violence and its impact on different victim groups. The original dataset is publicly available on the city’s open data portal (link). The sample population includes all known and reported individual victims of serious violent index crimes within Chicago, aggregated and anonymized to protect privacy. However, there are several issues with how the data was collected. First, to protect victim anonymity, any row with fewer than three incidents per quarter is removed, which hides rare but critical events like domestic violence and hate crimes. Also, since the dataset only includes crimes reported to CPD, unreported incidents—especially among vulnerable populations—are missing. Additionally, by focusing only on FBI index crimes involving bodily harm, the dataset excludes other important types of violence, creating gaps in understanding the full scope of violence in Chicago.\nThis dataset is widely used for public safety monitoring, research, and supporting violence prevention initiatives. It serves as a foundational source for the Mayor’s Office Violence Reduction Dashboard, which provides up-to-date information on violent crime trends across the city. By including details such as whether a shooting occurred, demographic breakdowns, and crime classifications, the data helps city officials, community organizations, and researchers track violence trends, identify at-risk communities, and evaluate intervention strategies. Although no specific policies have been made directly from this dataset, the dashboard built from it helps guide community violence prevention and citywide interventions. Common questions asked about the dataset include which communities are most affected by violence, how trends change over time, and concerns about underreporting and data completeness."
  },
  {
    "objectID": "posts/2025-3-17-second-blog-post/second blog post.html#data-background",
    "href": "posts/2025-3-17-second-blog-post/second blog post.html#data-background",
    "title": "Second blog post",
    "section": "",
    "text": "The data comes from the City of Chicago’s government and is collected by the Chicago Police Department (CPD) to track and analyze violent crimes, with a specific focus on gun violence and its impact on different victim groups. The original dataset is publicly available on the city’s open data portal (link). The sample population includes all known and reported individual victims of serious violent index crimes within Chicago, aggregated and anonymized to protect privacy. However, there are several issues with how the data was collected. First, to protect victim anonymity, any row with fewer than three incidents per quarter is removed, which hides rare but critical events like domestic violence and hate crimes. Also, since the dataset only includes crimes reported to CPD, unreported incidents—especially among vulnerable populations—are missing. Additionally, by focusing only on FBI index crimes involving bodily harm, the dataset excludes other important types of violence, creating gaps in understanding the full scope of violence in Chicago.\nThis dataset is widely used for public safety monitoring, research, and supporting violence prevention initiatives. It serves as a foundational source for the Mayor’s Office Violence Reduction Dashboard, which provides up-to-date information on violent crime trends across the city. By including details such as whether a shooting occurred, demographic breakdowns, and crime classifications, the data helps city officials, community organizations, and researchers track violence trends, identify at-risk communities, and evaluate intervention strategies. Although no specific policies have been made directly from this dataset, the dashboard built from it helps guide community violence prevention and citywide interventions. Common questions asked about the dataset include which communities are most affected by violence, how trends change over time, and concerns about underreporting and data completeness."
  },
  {
    "objectID": "posts/2024-10-04-general-tips/general-tips.html",
    "href": "posts/2024-10-04-general-tips/general-tips.html",
    "title": "General Tips",
    "section": "",
    "text": "Use the tidyverse!\nYou don’t have to tell me what kind of chart something is. For example, the below is not a useful start to a sentence.\n\n\nThe graph presents a horizontal bar chart …\n\n\nEach page should be largely standalone.\nSometimes small tables or even inline numbers are better than a figure.\nRedundant colors (e.g. bar charts where each bar is a different color that doesn’t signify anything) often don’t help.\nProvide some details on how much data was removed in your cleaning process.\nUse the tidyverse!\nImagine I’m an impatient boss. Show me only what is important and relevant.\nCleaning must be entirely in R\nDon’t say things like, well if only everyone did like so and so than everything would be better. There are many things hiding behind the data that would go to explain things. This is an example of a bad conclusion.\n\n\nThe world could benefit form modeling its education systems after Europe’s.\n\nIt is fine to talk about how the European system is better according to certain metrics, but don’t assume that can easily translate to other regions.\n\nDon’t talk about your “journey”. The blog posts tell the story of your journey. The main pages should focus on the data and your findings.\n\n\nUse the tidyverse!\nNo but seriously, when asking ChatGPT to do your project for you, make sure to tell it to use the tidyverse, not base R."
  },
  {
    "objectID": "posts/2023-10-15-getting-started/getting-started.html",
    "href": "posts/2023-10-15-getting-started/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "Below, the items marked with [[OP]] should only be done by one person on the team.\n\nTo get started\n\n[[OP]] One person from the team should click the Github Classroom link on Teams.\n[[OP]] That person types in the group name for their group.\nThe rest of the team now clicks the Github Classroom link and selects their team from the dropdown list.\nFinally, each of you can clone the repository to your laptop like a normal assignment.\n\n\n\nSetting up the site\n\n[[OP]] Open the terminal and run quarto publish gh-pages.\n[[OP]] Select Yes to the prompt:  ? Publish site to https://sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME/ using gh-pages? (Y/n)\n[[OP]] Wait for the process to finish.\nOnce it is done, you can go to the URL it asked you about to see your site.\n\nNote: This is the process you will use every time you want to update your published site. Make sure to always follow the steps below for rendering, previewing, and committing your changes before doing these publish steps. Anyone can publish in the future.\n\n\nCustomize your site\n\n[[OP]] Open the _quarto.yml file and update the title to include your team name.\n[[OP]] Go to the about.qmd and remove the TF’s and professor’s names.\nadd your own along with a short introduction and a link to your Github user page.\n[[OP]] Render the site.\n[[OP]] Check and make sure you didn’t get any errors.\n[[OP]] Commit your changes and push.\n[[OP]] Repeat the steps under Setting up your site.\n\nOnce one person is done with this, each teammate in the group can, in turn, repeat steps 3-7. Before doing so, make sure to pull the changes from teammates before starting to make new changes. (We’ll talk soon about ways to organize your work and resolve conflicts.)\n\n\nStart your first post\n\nTo start your first post first, run remotes::install_github(\"sussmanbu/quartopost\") in your Console.\n[[OP]] Run quartopost::quartopost() (or click Addins-&gt;Create Quarto Post, or use C-Shift-P, type “Create Quarto” and press enter to run the command).\n\nNow you can start working on your post. You’ll want to render your post to see what it will look like on the site.\n\nEvery time you want to make a new post, you can repeat step 2 above.\nWhen you want to publish your progress, follow steps 4-7 from Customize your site.\n\nFinally, make sure to read through everything on this site which has the directions and rubric for the final project."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Final Project due May 5, 2024 at 11:59pm.\nThis comes from the index.qmd file.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4thBlogPost\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5thBlogPost\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeventh blog post\n\n\n\n\n\n\n\n\nThis post is the seventh blog post for group 12. \n\n\n\n\n\nApr 22, 2025\n\n\nBHZZ\n\n\n\n\n\n\n\n\n\n\n\n\nSixth blog post\n\n\n\n\n\n\n\n\nThis post is the sixth blog post for group 12. \n\n\n\n\n\nApr 14, 2025\n\n\nBHZZ\n\n\n\n\n\n\n\n\n\n\n\n\nFifth blog post\n\n\n\n\n\n\n\n\nThis post is the fifth blog post for group 12. \n\n\n\n\n\nApr 7, 2025\n\n\nBHZZ\n\n\n\n\n\n\n\n\n\n\n\n\nFourth blog post\n\n\n\n\n\n\n\n\nThis post is the Fourth blog post for group 12. \n\n\n\n\n\nMar 31, 2025\n\n\nBHZZ\n\n\n\n\n\n\n\n\n\n\n\n\nThird blog post\n\n\n\n\n\n\n\n\nThis post is the third blog post for group 12. \n\n\n\n\n\nMar 21, 2025\n\n\nBHZZ\n\n\n\n\n\n\n\n\n\n\n\n\nSecond blog post\n\n\n\n\n\n\n\n\nThis post is the second blog post for group 12. \n\n\n\n\n\nMar 17, 2025\n\n\nBHZZ\n\n\n\n\n\n\n\n\n\n\n\n\nFirst blog post\n\n\n\n\n\n\n\n\nThis post is the first blog post for group 12. \n\n\n\n\n\nFeb 24, 2025\n\n\nBHZZ\n\n\n\n\n\n\n\n\n\n\n\n\nGeneral Tips\n\n\n\n\n\nSome small but important tips to follow. \n\n\n\n\n\nOct 4, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nExamples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nGetting started\n\n\n\n\n\n\n\n\nDirections to set up your website and create your first post. \n\n\n\n\n\nFeb 23, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Team Meeting\n\n\n\n\n\n\n\n\nThis post details the steps you’ll take for your first team meeting. \n\n\n\n\n\nFeb 21, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "This comes from the file data.qmd.\nYour first steps in this project will be to find data to work on.\nI recommend trying to find data that interests you and that you are knowledgeable about. A bad example would be if you have no interest in video games but your data set is about video games. I also recommend finding data that is related to current events, social justice, and other areas that have an impact.\nInitially, you will study one dataset but later you will need to combine that data with another dataset. For this reason, I recommend finding data that has some date and/or location components. These types of data are conducive to interesting visualizations and analysis and you can also combine this data with other data that also has a date or location variable. Data from the census, weather data, economic data, are all relatively easy to combine with other data with time/location components."
  },
  {
    "objectID": "data.html#what-makes-a-good-data-set",
    "href": "data.html#what-makes-a-good-data-set",
    "title": "Data",
    "section": "What makes a good data set?",
    "text": "What makes a good data set?\n\nData you are interested in and care about.\nData where there are a lot of potential questions that you can explore.\nA data set that isn’t completely cleaned already.\nMultiple sources for data that you can combine.\nSome type of time and/or location component."
  },
  {
    "objectID": "data.html#where-to-keep-data",
    "href": "data.html#where-to-keep-data",
    "title": "Data",
    "section": "Where to keep data?",
    "text": "Where to keep data?\nBelow 50mb: In dataset folder\nAbove 50mb: In dataset-ignore folder which you will have to create manually. This folder will be ignored by git so you’ll have to manually sync these files across your team.\n\nSharing your data\nFor small datasets (&lt;50mb), you can use the dataset folder that is tracked by github. Stage and commit the files just like you would any other file.\nFor larger datasets, you’ll need to create a new folder in the project root directory named dataset-ignore. This will be ignored by git (based off the .gitignore file in the project root directory) which will help you avoid issues with Github’s size limits. Your team will have to manually make sure the data files in dataset-ignore are synced across team members.\nYour clean_data.R file in the scripts folder is the file where you will import the raw data that you download, clean it, and write .rds file(s) (using write_rds) that you’ll load in your analysis page. If desirable, you can have multiple scripts that produce different derived data sets, just make sure to link to them on this page.\nYou should never use absolute paths (eg. /Users/danielsussman/path/to/project/ or C:\\MA415\\\\Final_Project\\). Instead, use the here function from the here package to avoid path problems.\n\n\nClean data script\nThe idea behind this file is that someone coming to your website could largely replicate your analyses after running this script on the original data sets to clean them. This file might create a derivative data set that you then use for your subsequent analysis. Note that you don’t need to run this script from every post/page. Instead, you can load in the results of this script, which will usually be .rds files. In your data page you’ll describe how these results were created. If you have a very large data set, you might save smaller data sets that you can use for exploration purposes. To link to this file, you can use [cleaning script](/scripts/clean_data.R) wich appears as cleaning script."
  },
  {
    "objectID": "data.html#rubric-on-this-page",
    "href": "data.html#rubric-on-this-page",
    "title": "Data",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nDescribe where/how to find data.\n\nYou must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.\nWhy was the data collected/curated? Who put it together? (This is important, if you don’t know why it was collected then that might not be a good dataset to look at.\n\nDescribe the different data files used and what each variable means.\n\nIf you have many variables then only describe the most relevant ones, possibly grouping together variables that are similar, and summarize the rest.\nUse figures or tables to help explain the data. For example, showing a histogram or bar chart for a particularly important variable can provide a quick overview of the values that variable tends to take.\n\nDescribe any cleaning you had to do for your data.\n\nYou must include a link to your clean_data.R file.\nRename variables and recode factors to make data more clear.\nAlso, describe any additional R packages you used outside of those covered in class.\nDescribe and show code for how you combined multiple data files and any cleaning that was necessary for that.\nSome repetition of what you do in your clean_data.R file is fine and encouraged if it helps explain what you did.\n\nOrganization, clarity, cleanliness of the page\n\nMake sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.\nThis page should be self-contained."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This comes from the file analysis.qmd.\nWe describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You’ll also reflect on next steps and further analysis.\nThe audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.\nWhile the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.\nThe style of this paper should aim to be that of an academic paper. I don’t expect this to be of publication quality but you should keep that aim in mind. Avoid using “we” too frequently, for example “We also found that …”. Describe your methodology and your findings but don’t describe your whole process."
  },
  {
    "objectID": "analysis.html#note-on-attribution",
    "href": "analysis.html#note-on-attribution",
    "title": "Analysis",
    "section": "Note on Attribution",
    "text": "Note on Attribution\nIn general, you should try to provide links to relevant resources, especially those that helped you. You don’t have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don’t need a formal citation.\nIf you are directly quoting from a source, please make that clear. You can show long quotes using &gt; like this\n&gt; To be or not to be.\n\nTo be or not to be."
  },
  {
    "objectID": "analysis.html#rubric-on-this-page",
    "href": "analysis.html#rubric-on-this-page",
    "title": "Analysis",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nIntroduce what motivates your Data Analysis (DA)\n\nWhich variables and relationships are you most interested in?\nWhat questions are you interested in answering?\nProvide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n\nModeling and Inference\n\nThe page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\nExplain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)\nDescribe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n\nExplain the flaws and limitations of your analysis\n\nAre there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n\nClarity Figures\n\nAre your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\nEach figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\nDefault lm output and plots are typically not acceptable.\n\nClarity of Explanations\n\nHow well do you explain each figure/result?\nDo you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n\nOrganization and cleanliness.\n\nMake sure to remove excessive warnings, hide all code, organize with sections or multiple pages, use bullets, etc.\nThis page should be self-contained, i.e. provide a description of the relevant data."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Team BHZZ. The members of this team are below."
  },
  {
    "objectID": "about.html#chidong-zhou",
    "href": "about.html#chidong-zhou",
    "title": "About",
    "section": "Chidong Zhou",
    "text": "Chidong Zhou\nChidong is a senior student in Econ&Math and is the member for final project group 12."
  },
  {
    "objectID": "about.html#shivani-bedre",
    "href": "about.html#shivani-bedre",
    "title": "About",
    "section": "Shivani Bedre",
    "text": "Shivani Bedre\nShivani is a junior student in Mathematics & Statistics and a member of final project group 12."
  },
  {
    "objectID": "about.html#chloe-he",
    "href": "about.html#chloe-he",
    "title": "About",
    "section": "Chloe He",
    "text": "Chloe He\nChloe is a junior student in Data Science and Business and a member of final project group 12."
  },
  {
    "objectID": "about.html#yunxiang-zhang",
    "href": "about.html#yunxiang-zhang",
    "title": "About",
    "section": "Yunxiang Zhang",
    "text": "Yunxiang Zhang\nYunxiang is a first year master student in MSSP program and a member of final project group 12\n\n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Big Picture",
    "section": "",
    "text": "This comes from the file big_picture.qmd.\nThink of this page as your 538/Upshot style article. This means that you should try to tell a story through the data and your analysis. Read articles from those sites and similar sites to get a feeling for what they are like. Try to write in the style of a news or popular article. Importantly, this page should be geared towards the general public. You shouldn’t assume the reader understands how to interpret a linear regression or a complicated plot. Focus on interpretation and visualizations."
  },
  {
    "objectID": "big_picture.html#rubric-on-this-page",
    "href": "big_picture.html#rubric-on-this-page",
    "title": "Big Picture",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\n\nTitle\n\nYour big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.\n\nClarity of Explanation\n\nYou should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don’t go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.\nEach figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.\n\nCreativity\n\nDo your best to make things interesting. Think of a how a news article or a magazine story might draw you in. Think of how each part of your analysis supports the previous part or provides a different perspective.\n\nInteractive component\n\nQuality and ease of use of the interactive components. Is it clear what can be explored using your interactive components? Does it enhance and reinforce your conclusions?\n\nThis page should be self-contained.\n\nNote: This page should have no code visible, i.e. use #| echo: FALSE."
  },
  {
    "objectID": "big_picture.html#rubric-other-components",
    "href": "big_picture.html#rubric-other-components",
    "title": "Big Picture",
    "section": "Rubric: Other components",
    "text": "Rubric: Other components\n\nVideo Recording\nMake a video recording (probably using Zoom) demonstrating your interactive components. You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA. This video should be no longer than 4 minutes. Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website. This can be presented by any subset of the team members.\n\n\nRest of the Site\nFinally, here are important things to keep in mind for the rest of the site.\nThe main title of your page is informative. Each post has an author/description/informative title. All lab required posts are present. Each page (including the home page) has a nice featured image associated with it. Your about page is up to date and clean. You have removed the generic posts from the initial site template."
  },
  {
    "objectID": "dataset_ignore/ignore_me.html",
    "href": "dataset_ignore/ignore_me.html",
    "title": "ignore_me",
    "section": "",
    "text": "testing! ignore me!"
  },
  {
    "objectID": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "href": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "title": "First Team Meeting",
    "section": "",
    "text": "These are the steps that you will take today to get started on your project. Today, you will just be brainstorming, and then next week, you’ll get started on the main aspects of the project.\n\nStart by introducing yourselves to each other. I also recommend creating a private channel on Microsoft Teams with all your team members. This will be a place that you can communicate and share ideas, code, problems, etc.\nDiscuss what aspects of the project each of you are more or less excited about. These include\n\nCollecting, cleaning, and munging data ,\nStatistical Modeling,\nVisualization,\nWriting about analyses, and\nManaging and reviewing team work.\n\nBased on this, discuss where you feel your strengths and weaknesses might be.\nNext, start brainstorming questions you hope to answer as part of this project. This question should in some way be addressing issues around racial disparities. The questions you come up with should be at the level of the question we started with when exploring the HMDA data. (“Are there differences in the ease of securing a loan based on the race of the applicant?”) You’ll revise your questions a lot over the course of the project. Come up with a few questions that your group might be interested in exploring.\nBased on these questions, start looking around for data that might help you analyze this. If you are looking at U.S. based data, data.gov is a good source and if you are looking internationally, I recommend checking out the World Bank. Also, try Googling for data. Include “data set” or “dataset” in your query. You might even include “CSV” or some other format. Using “data” by itself in your query often doesn’t work too well. Spend some time searching for data and try to come up with at least three possible data sets. (For your first blog post, you’ll write short proposals about each of them that I’ll give feedback on.)\nCome up with a team name. Next week, I’ll provide the Github Classroom assignment that will be where you work on your final project and you’ll have to have your team name finalized by then. Your project will be hosted online at the website with a URL like sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME.\n\nNext time, you’ll get your final project website set up and write your first blog post."
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html",
    "href": "posts/2023-12-20-examples/examples.html",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "href": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2025-2-24-first-blog-post/first blog post.html",
    "href": "posts/2025-2-24-first-blog-post/first blog post.html",
    "title": "First blog post",
    "section": "",
    "text": "School Attendance by Student Group and District, 2021-2022\nhttps://catalog.data.gov/dataset/school-attendance-by-student-group-and-district-2021-2022\n\nData size: 2,019 rows and 12 columns\nPurpose: The dataset was collected to analyze student attendance rates across different public school districts in Connecticut for the 2021-2022 school year.\nCollection Method: The Connecticut State Department of Education (CSDE) likely gathered this data from public schools’ attendance records. It includes breakdowns by student demographics, districts, and statewide averages.\nUse Case: The data helps identify attendance disparities among different student groups, supporting policy-making, funding allocations, and targeted interventions for at-risk students. For this project, we will work on analyzing the racial disparities\nQuestion: Attendance differences by race/ethnicity.\nPossible challenge: some missing data.\n\nAdult Depression (LGHC Indicator) - Catalog (data.gov), 2012-2018\nhttps://catalog.data.gov/dataset/adult-depression-lghc-indicator-627e3\n\nData size : 162 rows, 8 columns\nPurpose: The data was collected as part of the California Behavioral Risk Factor Surveillance Survey to answer the question “Has a doctor, nurse, or other health professional EVER told you that you have a depressive disorder (including depression, major depression, dysthymia, or minor depression)?”\nCollection Method: Telephone interviews\nAre we able to clean the data: Yes\nMain questions hope to address: Has the proportion of adults diagnosed with depression changed between 2012 and 2018 based on race or other factors\nChallenges: Data and weighting come from the California Department of Finance, there may be differences from national reports. Also self-reporting could lead to underreporting or overreporting.\n\nViolence Reduction - Victim Demographics - Aggregated\nViolence Reduction - Victim Demographics - Aggregated - Catalog\n\nData size: 55676 row 11 col\nPurpose: This dataset contains aggregate data on violent index victimizations at the quarter level of each year (i.e., January – March, April – June, July – September, October – December), from 2001 to the present (1991 to present for Homicides), with a focus on those related to gun violence.\nCollection methods: The data is extracted from the Chicago Police Department’s (CPD) case system and synchronized with the data on the Mayor’s Office Violence Reduction Dashboard.\nAre we able to clean the data: Yes\nMain question to address: Do different ethnic groups have a particular preference for certain types of crimes, and is this preference related to specific geographic areas?\nChallenge: To protect the privacy of victims, some data has been obfuscated, reducing the efficiency and accuracy of the dataset. There is a significant amount of “Unknown” values, which may require data supplementation or cleaning."
  },
  {
    "objectID": "posts/2025-2-24-first-blog-post/first blog post.html#datasets-selection",
    "href": "posts/2025-2-24-first-blog-post/first blog post.html#datasets-selection",
    "title": "First blog post",
    "section": "",
    "text": "School Attendance by Student Group and District, 2021-2022\nhttps://catalog.data.gov/dataset/school-attendance-by-student-group-and-district-2021-2022\n\nData size: 2,019 rows and 12 columns\nPurpose: The dataset was collected to analyze student attendance rates across different public school districts in Connecticut for the 2021-2022 school year.\nCollection Method: The Connecticut State Department of Education (CSDE) likely gathered this data from public schools’ attendance records. It includes breakdowns by student demographics, districts, and statewide averages.\nUse Case: The data helps identify attendance disparities among different student groups, supporting policy-making, funding allocations, and targeted interventions for at-risk students. For this project, we will work on analyzing the racial disparities\nQuestion: Attendance differences by race/ethnicity.\nPossible challenge: some missing data.\n\nAdult Depression (LGHC Indicator) - Catalog (data.gov), 2012-2018\nhttps://catalog.data.gov/dataset/adult-depression-lghc-indicator-627e3\n\nData size : 162 rows, 8 columns\nPurpose: The data was collected as part of the California Behavioral Risk Factor Surveillance Survey to answer the question “Has a doctor, nurse, or other health professional EVER told you that you have a depressive disorder (including depression, major depression, dysthymia, or minor depression)?”\nCollection Method: Telephone interviews\nAre we able to clean the data: Yes\nMain questions hope to address: Has the proportion of adults diagnosed with depression changed between 2012 and 2018 based on race or other factors\nChallenges: Data and weighting come from the California Department of Finance, there may be differences from national reports. Also self-reporting could lead to underreporting or overreporting.\n\nViolence Reduction - Victim Demographics - Aggregated\nViolence Reduction - Victim Demographics - Aggregated - Catalog\n\nData size: 55676 row 11 col\nPurpose: This dataset contains aggregate data on violent index victimizations at the quarter level of each year (i.e., January – March, April – June, July – September, October – December), from 2001 to the present (1991 to present for Homicides), with a focus on those related to gun violence.\nCollection methods: The data is extracted from the Chicago Police Department’s (CPD) case system and synchronized with the data on the Mayor’s Office Violence Reduction Dashboard.\nAre we able to clean the data: Yes\nMain question to address: Do different ethnic groups have a particular preference for certain types of crimes, and is this preference related to specific geographic areas?\nChallenge: To protect the privacy of victims, some data has been obfuscated, reducing the efficiency and accuracy of the dataset. There is a significant amount of “Unknown” values, which may require data supplementation or cleaning."
  },
  {
    "objectID": "posts/2025-3-31-forth-blog-post/4thBlogPost.html",
    "href": "posts/2025-3-31-forth-blog-post/4thBlogPost.html",
    "title": "Fourth blog post",
    "section": "",
    "text": "In earlier exploration, we observed two major patterns from the Chicago violent crime dataset:\n\nGender Disparities: Males are significantly more likely to be victims of most violent crimes (assault, battery, homicide, robbery). However, females are disproportionately represented in sexual assault and human trafficking cases.\nRacial Disparities: Black (BLK) individuals, especially males, consistently account for the highest number of victims in battery and homicide cases. However, when we break victim data down by both race and sex, more nuanced patterns emerge.\n\nTo explore these trends further, we selected two visualizations:\nFigure 1: Violent Crime Victimization by Sex\nThis figure clearly shows that males dominate in victim counts across nearly all violent crime categories—except for criminal sexual assault, where female victims outnumber male victims by more than double. This prompted us to investigate whether sex is a strong statistical predictor of being a sexual assault victim.\n\nFigure 2: Violent Crime Victimization by Race and Sex\nBy plotting both race and sex, we found strong intersectional patterns. For example, Black males are disproportionately affected by homicide and battery, while White Hispanic and White females appear more frequently in sexual assault cases. This raises the question: how do race and sex interact in shaping the risk of being a sexual assault victim?\n\nLogistic Regression Model: Predicting Sexual Assault Victimization\nTo better understand this relationship, we fit a logistic regression model with the following specification:\n\nResponse variable: IS_SEXUAL_ASSAULT (1 if the victim was recorded as such, 0 otherwise)\nPredictors: SEX, RACE, and their interaction (SEX * RACE)\n\nWe used ggeffects::ggpredict() to visualize the predicted probabilities.\nFigure 3: Predicted Probability of Being a Sexual Assault Victim\nThis model output confirms our earlier observations:\n\nAcross all racial groups, females have significantly higher predicted probabilities of being sexual assault victims than males.\nMales have near-zero probabilities, indicating that sex is by far the strongest predictor.\nAmong females, the probability varies by race:\n\nHighest: White Hispanic (WWH) and White Non-Hispanic (WHI)\nLower: Asian/Pacific Islander (API) and Indigenous (I)\n\n\nThese insights support the idea that both gender and race interact in shaping crime victimization risk—especially for sensitive categories like sexual assault.\n\nTakeaways & Next Steps\n\nWe validated major EDA trends with modeling: being female greatly increases the odds of being a sexual assault victim, with race playing a secondary but still notable role.\nThese findings emphasize the importance of intersectional analysis when working with demographic data.\nFor next steps, we plan to:\n\nInclude year as a variable to assess trends over time\nExplore other crime categories (e.g., battery, robbery)\nConsider other predictors such as age, domestic violence flag, or gun involvement"
  },
  {
    "objectID": "posts/2025-3-31-forth-blog-post/4thBlogPost.html#key-trends-identified-through-eda",
    "href": "posts/2025-3-31-forth-blog-post/4thBlogPost.html#key-trends-identified-through-eda",
    "title": "Fourth blog post",
    "section": "",
    "text": "In earlier exploration, we observed two major patterns from the Chicago violent crime dataset:\n\nGender Disparities: Males are significantly more likely to be victims of most violent crimes (assault, battery, homicide, robbery). However, females are disproportionately represented in sexual assault and human trafficking cases.\nRacial Disparities: Black (BLK) individuals, especially males, consistently account for the highest number of victims in battery and homicide cases. However, when we break victim data down by both race and sex, more nuanced patterns emerge.\n\nTo explore these trends further, we selected two visualizations:\nFigure 1: Violent Crime Victimization by Sex\nThis figure clearly shows that males dominate in victim counts across nearly all violent crime categories—except for criminal sexual assault, where female victims outnumber male victims by more than double. This prompted us to investigate whether sex is a strong statistical predictor of being a sexual assault victim.\n\nFigure 2: Violent Crime Victimization by Race and Sex\nBy plotting both race and sex, we found strong intersectional patterns. For example, Black males are disproportionately affected by homicide and battery, while White Hispanic and White females appear more frequently in sexual assault cases. This raises the question: how do race and sex interact in shaping the risk of being a sexual assault victim?\n\nLogistic Regression Model: Predicting Sexual Assault Victimization\nTo better understand this relationship, we fit a logistic regression model with the following specification:\n\nResponse variable: IS_SEXUAL_ASSAULT (1 if the victim was recorded as such, 0 otherwise)\nPredictors: SEX, RACE, and their interaction (SEX * RACE)\n\nWe used ggeffects::ggpredict() to visualize the predicted probabilities.\nFigure 3: Predicted Probability of Being a Sexual Assault Victim\nThis model output confirms our earlier observations:\n\nAcross all racial groups, females have significantly higher predicted probabilities of being sexual assault victims than males.\nMales have near-zero probabilities, indicating that sex is by far the strongest predictor.\nAmong females, the probability varies by race:\n\nHighest: White Hispanic (WWH) and White Non-Hispanic (WHI)\nLower: Asian/Pacific Islander (API) and Indigenous (I)\n\n\nThese insights support the idea that both gender and race interact in shaping crime victimization risk—especially for sensitive categories like sexual assault.\n\nTakeaways & Next Steps\n\nWe validated major EDA trends with modeling: being female greatly increases the odds of being a sexual assault victim, with race playing a secondary but still notable role.\nThese findings emphasize the importance of intersectional analysis when working with demographic data.\nFor next steps, we plan to:\n\nInclude year as a variable to assess trends over time\nExplore other crime categories (e.g., battery, robbery)\nConsider other predictors such as age, domestic violence flag, or gun involvement"
  },
  {
    "objectID": "posts/2025-4-22-seventh-blog-post/7thblogpost.html",
    "href": "posts/2025-4-22-seventh-blog-post/7thblogpost.html",
    "title": "Seventh blog post",
    "section": "",
    "text": "Run in console\ninstall.packages(“tidycensus”)\nDashboard#1: Race Representation in Chicago: Crime Victims vs Population by year 2021, 2022, and 2023\n\nlibrary(tidycensus)\n\n# importing census data for 2021, 202, and 2022\ncensus_api_key(\"c4df8a0f6334859b29db81b64e1ac48b98038f19\", overwrite = TRUE)\n\nTo install your API key for use in future sessions, run this function with `install = TRUE`.\n\n# 2021\ndata2021 &lt;- get_acs(\n  geography = \"place\",\n  variables = c(\n    total = \"B03002_001\",\n    white = \"B03002_003\",\n    black = \"B03002_004\",\n    native = \"B03002_005\",\n    asian = \"B03002_006\",\n    hispanic = \"B03002_012\"\n  ),\n  state = \"IL\",\n  year = 2021,\n  survey = \"acs1\"\n)\n\nGetting data from the 2021 1-year ACS\n\n\nThe 1-year ACS provides data for geographies with populations of 65,000 and greater.\n\nsaveRDS(data2021, \"dataset/chicago_census_2021.rds\")\n\n# 2022\ndata2022 &lt;- get_acs(\n  geography = \"place\",\n  variables = c(\n    total = \"B03002_001\",\n    white = \"B03002_003\",\n    black = \"B03002_004\",\n    native = \"B03002_005\",\n    asian = \"B03002_006\",\n    hispanic = \"B03002_012\"\n  ),\n  state = \"IL\",\n  year = 2022,\n  survey = \"acs1\"\n)\n\nGetting data from the 2022 1-year ACS\nThe 1-year ACS provides data for geographies with populations of 65,000 and greater.\n\nsaveRDS(data2022, \"dataset/chicago_census_2022.rds\")\n\n# 2023\ndata2023 &lt;- get_acs(\n  geography = \"place\",\n  variables = c(\n    total = \"B03002_001\",\n    white = \"B03002_003\",\n    black = \"B03002_004\",\n    native = \"B03002_005\",\n    asian = \"B03002_006\",\n    hispanic = \"B03002_012\"\n  ),\n  state = \"IL\",\n  year = 2023,\n  survey = \"acs1\"\n)\n\nGetting data from the 2023 1-year ACS\nThe 1-year ACS provides data for geographies with populations of 65,000 and greater.\n\nsaveRDS(data2023, \"dataset/chicago_census_2023.rds\")\n\n\nlibrary(shiny)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr)\nlibrary(readr)\n\n\n# ==== UI ====\nui &lt;- fluidPage(\n  titlePanel(\"Race Representation in Chicago: Crime Victims vs Population\"),\n  sidebarLayout(\n    sidebarPanel(\n      selectInput(\"year\", \"Select Year:\", choices = c(2021, 2022, 2023), selected = 2021)\n    ),\n    mainPanel(\n      plotOutput(\"race_plot\"),\n      br(),\n      textOutput(\"note\")\n    )\n  )\n)\n\n======= Progress We’ve explored the dataset and started cleaning it in R while identifying variables like arrest date, borough, offense description, and demographic details that will be central to the interactive. Our next step is to build the Shiny app that includes both a time trend chart and dropdown filters for user exploration.\nInteractive We’re creating the interactive dashboard called Arrest Trends Explorer, which will let users explore NYPD arrest data from different angles. - The goal is to make the data accessible and engaging by allowing users to view big picture trends like total arrests over time. - Users will also be able to “zoom in” on more specific patterns. - Users will be able to filter the data by borough, offense type, and demographic categories such as age or race. - This gives them the power to investigate questions that are personally meaningful or socially relevant, such as whether certain neighborhoods experience more arrests for specific types of crimes, or how trends shift over the course of a year.\n\n# ==== Server ====\nserver &lt;- function(input, output) {\n  # Load violence data once\n  violence_data &lt;- read_csv(\"dataset/Violence_clean_missing.csv\", show_col_types = FALSE)\n\n  output$race_plot &lt;- renderPlot({\n    # ==== 1. Load census data ====\n    census_raw &lt;- readRDS(paste0(\"dataset/chicago_census_\", input$year, \".rds\"))\n\n    census_df &lt;- census_raw |&gt;\n      filter(NAME == \"Chicago city, Illinois\") |&gt;\n      select(variable, estimate) |&gt;\n      pivot_wider(names_from = variable, values_from = estimate) |&gt;\n      mutate(\n        WHI = white / total * 100,\n        BLK = black / total * 100,\n        HIS = hispanic / total * 100,\n        API = asian / total * 100,\n        I   = native / total * 100\n      ) |&gt;\n      select(WHI, BLK, HIS, API, I) |&gt;\n      pivot_longer(cols = everything(), names_to = \"RACE\", values_to = \"Proportion\") |&gt;\n      mutate(Source = \"Census\")\n\n    # ==== 2. Create crime victim data ====\n    victim_df &lt;- violence_data |&gt;\n      filter(Year == input$year) |&gt;\n      filter(!(RACE %in% c(\"UNKNOWN\", \"S\"))) |&gt;\n      mutate(RACE = ifelse(RACE %in% c(\"WBH\", \"WWH\"), \"HIS\", RACE)) |&gt;\n      group_by(RACE) |&gt;\n      summarise(Count = n(), .groups = \"drop\") |&gt;\n      mutate(Proportion = Count / sum(Count) * 100,\n             Source = \"Crime Victims\") |&gt;\n      select(RACE, Proportion, Source)\n    \n    \n    # ==== 3. Combine and plot ====\n    combined &lt;- bind_rows(census_df, victim_df)\n\n    ggplot(combined, aes(x = RACE, y = Proportion, fill = Source)) +\n      geom_col(position = \"dodge\") +\n      labs(title = paste(\"Race Representation in Chicago (\", input$year, \")\", sep = \"\"),\n           x = \"Race\", y = \"Proportion (%)\") +\n      theme_minimal()\n  })\n\n  # Add a note\n  output$note &lt;- renderText({\n    paste0(\"Note: Population data for \", input$year,\n           \" comes from the U.S. Census ACS 1-Year Estimates. \",\n           \"Crime data reflects victim demographics recorded by CPD in the same year.\")\n  })\n}\n\n\n# ==== Run App ====\nshinyApp(ui = ui, server = server)\n\nShiny applications not supported in static R Markdown documents\n\n\nDashboard#2:\n\nviolence_data &lt;- read_csv(\"dataset/Violence_clean_missing.csv\", show_col_types = FALSE)\n\n\n# ========== UI ==========\nui2 &lt;- fluidPage(\n  titlePanel(\"Victim Demographics by Crime Type\"),\n  sidebarLayout(\n    sidebarPanel(\n      selectInput(\"crime_type\", \"Select Crime Type:\",\n                  choices = unique(violence_data$PRIMARY_TYPE),\n                  selected = \"BATTERY\"),\n      checkboxGroupInput(\"sex\", \"Select Gender:\",\n                         choices = unique(violence_data$SEX),\n                         selected = c(\"M\", \"F\")),\n      checkboxGroupInput(\"race\", \"Select Race:\",\n                         choices = unique(violence_data$RACE),\n                         selected = c(\"BLK\", \"WHI\", \"HIS\", \"API\"))\n    ),\n    mainPanel(\n      plotOutput(\"distPlot\")\n    )\n  )\n)\n\n\n# ========== SERVER ==========\nserver2 &lt;- function(input, output) {\n  output$distPlot &lt;- renderPlot({\n    filtered &lt;- violence_data |&gt;\n      filter(PRIMARY_TYPE == input$crime_type,\n             SEX %in% input$sex,\n             RACE %in% input$race)\n\n    ggplot(filtered, aes(x = SEX, fill = RACE)) +\n      geom_bar(position = \"stack\") +\n      labs(\n        title = paste(\"Victim Gender-Race Distribution for\", input$crime_type),\n        x = \"Gender\", y = \"Number of Victims\", fill = \"Race\"\n      ) +\n      theme_minimal()\n  })\n}\n\n\n# ==== Run App ====\nshinyApp(ui2, server2)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "posts/2025-4-7-fifth-blog-post/5thblogpost.html",
    "href": "posts/2025-4-7-fifth-blog-post/5thblogpost.html",
    "title": "Fifth blog post",
    "section": "",
    "text": "Additional Dataset:\nhttps://data.census.gov/table/ACSST1Y2023.S0601?q=Chicago+Demographics\nWe combined our violent crime victim data with 2023 ACS 1-Year estimates for Chicago, which provide demographic breakdowns of sex and race across the city.\nCombining the data:\nWe can use the TIME_PERIOD, RACE, and AGE variables in the victim dataset to connect with the RACE, AGE, and YEAR variables in this demographics dataset. The new dataset containing the variables of marital status, education level, personal income, and poverty status would provide more information and probably give more insights into the reasons for the crime conviction.\nInitial findings:\nAfter briefly looking through the new dataset, we found that while the black individuals make up only 27.9% of the population, they account for over 50% of homicide and battery victims. Other than that, as females represent around 51.5% of the population, in the sexual assault crimes, they are disproportionately represented, which will be the part we will continue exploring the reasons behind.\nPossible challenges and Next Steps:\nSince the race categorization in the new dataset is different from the victim data, and we are not quite sure about some race types in the victim data, it may be a problem we need to keep working on. And then we will start working on combining the data, making some visuals, and interpreting the results."
  }
]