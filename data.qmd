---
title: Data
description: We describe the sources of our data and the cleaning process.
toc: true
draft: false
---

![](images/data-import-cheatsheet-thumbs.png)


# Data Overview and Cleaning

## 1. Data Source and Context

- **Primary Dataset**: [Violence Reduction - Victim Demographics - Aggregated](https://data.cityofchicago.org/Public-Safety/Violence-Reduction-Victim-Demographics-Aggregated/gj7a-742p/about_data)
- **Publisher**: City of Chicago, collected by the **Chicago Police Department (CPD)**.
- **Purpose**: To track violent crime trends, especially gun-related victimization, across demographic groups to support public safety monitoring, resource allocation, and violence prevention strategies.
- **Curation Note**: The dataset is anonymized and aggregated quarterly to protect victim privacy. Rows with fewer than 3 incidents per quarter are removed, possibly underrepresenting rare or sensitive events (e.g., domestic violence, hate crimes).

## 2. Description of Data Files and Key Variables

### Datasets Used

1. `Violence_Reduction_Victim_Demographics_Aggregated`
2. 2023 ACS 1-Year Estimates for Chicago Demographics  
   [Source](https://data.census.gov/table/ACSST1Y2023.S0601?q=Chicago+Demographics)

### Key Variables (from Violence Dataset)

| Variable Name           | Description |
|-------------------------|-------------|
| `PRIMARY_TYPE`          | Type of violent crime (e.g., battery, homicide) |
| `SEX`                   | Victim’s gender (`M`, `F`, `UNKNOWN`) |
| `RACE`                  | Victim’s race (e.g., `BLK`, `WHI`, `WWH`, `API`, `UNKNOWN`) |
| `AGE`                   | Victim’s age group (aggregated) |
| `TIME_PERIOD`           | Quarter and year of incident |
| `GUNSHOT_INJURY_I`      | Whether the victim was shot (`YES`, `NO`, `UNKNOWN`) |


## Data Cleaning Process and Documentation

This section outlines the full data cleaning procedure used to prepare the Chicago violence victimization dataset for analysis.

### Cleaning Objectives

The main goals of the cleaning process were to:
- Identify and handle missing or structurally unknown values.
- Recode and rename variables to improve interpretability.
- Ensure consistent formats for time-related and categorical fields.
- Maintain a self-contained, well-structured dataset ready for modeling and visualization.

### Packages Used

We used the following R packages beyond the base curriculum:
- `readr` – for efficient CSV import
- `dplyr` – for filtering, transforming, and joining datasets
- `ggplot2` – for data visualization
- `reshape2` – to structure matrix data for heatmap plotting
- `gridExtra` – for arranging multiple plots in a single layout

### Step 1: Import and Parse Data

We imported the dataset and extracted the year from the `TIME_PERIOD` field for time-based analysis. This allowed us to align police data with census years for comparative studies.

### Step 2: Detect and Separate Unknown Values

We identified unknown entries in key demographic and incident-related variables, such as `AGE`, `SEX`, `RACE`, `GUNSHOT_INJURY_I`, `PRIMARY_TYPE`, and others. The dataset was split into:
- A "clean" subset without any "UNKNOWN" values.
- A "dirty" subset containing one or more "UNKNOWN" entries, for further investigation.

### Step 3: Visualize Missingness

We visualized the frequency of "UNKNOWN" entries across variables and per row. This allowed us to:
- Identify that `GUNSHOT_INJURY_I` had a disproportionately high number of unknowns.
- Detect that most rows had only one missing value.

### Step 4: Recode Structural Missingness

According to the dataset documentation, shooting injury data before 2010 was not recorded for non-homicides and was marked as `"UNKNOWN"`. We recoded these values into a new category to distinguish them from truly missing data.

### Step 5: Examine Multi-Variable Missingness

We examined rows with exactly two unknown fields and used heatmaps to detect patterns of co-missing values. We found that these records often reflected cases where individuals refused to provide demographic information, especially `RACE` and `SEX`.

### Step 6: Final Filtering

To ensure analytic validity, we:
- Retained all rows with zero or one unknown value in the four critical columns (`AGE`, `SEX`, `RACE`, `GUNSHOT_INJURY_I`).
- Removed rows with two or more unknowns.
- Combined these cleaned rows with the previously clean dataset into a single final cleaned dataset.

### Renaming and Recoding

We created new variables and harmonized categorical values:
- Created `IS_SEXUAL_ASSAULT` as a binary indicator for modeling.
- Merged `WBH` and `WWH` racial codes into a unified `HIS` (Hispanic) category for compatibility with census data.
- Recoded all relevant categorical variables into factor types.

### Data Combination

We prepared a secondary dataset with demographic proportions for Chicago from the U.S. Census (ACS) for the years 1990–2020. These external data were structured into a compatible format to allow side-by-side comparisons with victimization proportions by race over time.

### Final Output

The result is a cleaned, structured dataset that:
- Minimizes bias from missing values.
- Preserves as much usable information as possible.
- Allows for demographic-based and time-based comparisons.
- Enables logistic modeling and visualization of race and sex effects on victimization patterns.

---